# LLM_info
Useful information about LLM and its environment is collected here

# Open source projects

1. [GGML](https://github.com/ggerganov/ggml): tensor library for machine learning
2. [Medusa](https://github.com/FasterDecoding/Medusa) is a simple framework that democratizes the acceleration techniques for LLM generation with multiple decoding heads.

# Frameworks

1. [LangChain](https://github.com/langchain-ai/langchain) is a framework for developing applications powered by large language models (LLMs)
2. [FireOptimizer](https://fireworks.ai/blog/fireoptimizer?utm_source=newsletter&utm_medium=email&utm_campaign=2024september)

# Common information in tutorials and blogs

## Optimization concepts
1. Speculative decoding:
 - [Speculative Decoding â€” Make LLM Inference Faster](https://medium.com/ai-science/speculative-decoding-make-llm-inference-faster-c004501af120)

## API
1. [OpenAI API](https://platform.openai.com/docs/api-reference/introduction)
2. [Using logprobs](https://cookbook.openai.com/examples/using_logprobs) from OpenAI

## Benchmarks
1. [LLM evals and benchmarking](https://osanseviero.github.io/hackerllama/blog/posts/llm_evals/)

# Papers

## Transformer and attention concepts

## Optimization concepts

## Quantization

## Performance benchmark

## Accuracy benchmark

## Other benchmarks

## LLM tech documents
